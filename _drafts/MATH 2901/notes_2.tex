\include{config/config}

\begin{document}
% ========== Edit your name here
\title{MATH 2901 Basic Probability Lecture Notes 2}
\author{Instructor: Richard Kleeman}
\date{}
\maketitle

%\medskip

% ========== Contents begin here ==============
\section{Random variables}
\begin{definition}
\textbf{A random variable} is a function $X: \Omega \to \R$ with the property that $\{ \omega\in \Omega \spacevert X(\omega) \leq x\} \in \mathcal{F}$ for each $x \in \R$. Such a function is said to be $\mathbf{\mathcal{F}}$\textbf{-measurable}. 
\end{definition}

\begin{example}
Tossing two dice. We define 
\begin{equation*}
    X = \begin{cases} 1 & \text{get double ($i=j$)} \\ 0 & \text{not double $(i\neq j)$} \end{cases}.
\end{equation*}
Then $X = (i,j) \in \R$.
\end{example}

\begin{remark}
We are interested in $g(x) = \Prob\{ \omega \spacevert X(\omega) = x \}$. But sometimes it doesn't work very well. Probability triplet is defined as $\{ \Omega, \mathcal{F}, \Prob \}$. If $\Omega$ is countable, then $g(x)$ is okay. But if $\Omega$ is uncountable like intervals, then $\Prob(X=x)$ doesn't make much sense because the cardinality is too large.
\end{remark}

\begin{definition}
The \textbf{distribution function} of a random variable $X$ is the function $F: \R \to 
[0, 1]$ given by $F(x) = \Prob(X \leq x)$. 
\end{definition}

\begin{example}
The distribution function of preceeding example is 
\begin{equation*}
    F(x) = \begin{cases} 0 & x \leq 0, \\ \frac{30}{36} & 0 < x \leq 1, \\ 1 & x > 1. \end{cases}
\end{equation*}
\end{example}

Notice that $\{ \omega \spacevert X(\omega) \leq x\}$ defines an event. It is an element in the corresponding $\sigma$-field. Denote $A(x) = \{ \omega \spacevert X(\omega) \leq x \}$. Along with $A(x)$, we can define
\begin{equation*}
    A^c(x) = \{ \omega \spacevert X(\omega) > x \}, \quad A(x, y) = A^c(x) \cap A(y) = \{ \omega \spacevert x < X(\omega) \leq y \}.
\end{equation*}
Tow points worth noting:
\begin{enumerate}[(a)]
    \item $F$ must be defined for \textbf{all} $x \in \R$.
    \item $A(x)$ should \textbf{belongs to} $\mathcal{F}$. Otherwise, we cannot talk about the probability of $\Prob(A(x))$. Then the definition of distribution function is meaningless.
\end{enumerate}

\begin{lemma}
A distribution function $F$ has the following properties:
\begin{enumerate}[(a)]
    \item $\lim_{x \to -\infty}F(x) = 0$, $\lim_{x\to\infty} F(x) = 1$,
    \item if $x < y$, then $F(x) \leq F(y)$,
    \item $F$ is right-continuous, that is $F(x+h) \to F(x)$ as $h \downarrow 0$. (left-continuous is not necessary)
\end{enumerate}
\end{lemma}

\begin{example}
\textbf{Indicator functions.} A particular class of Bernoulli variables is very useful in probability theory. Let $A$ be an event and let $I_A : \Omega \to \R$ be the indicator function of $A$; that is,
\begin{equation*}
    I_A(\omega) = \begin{cases} 1 & \text{if $\omega \in A$}, \\ 0 & \text{if $\omega \in A^c$}. \end{cases}
\end{equation*}
Then $I_A$ is a Bernoulli random variable taking the values 1 and 0 with probabilities $\Prob(A)$ and $\Prob(A^c)$ respectively. Suppose $\{B_i \spacevert i \in I\}$ is a family of disjoint events with $A \subseteq \bigcup_{i\in I} B_i$. Then 
\begin{equation*}
    I_A = \sum_{i} = I_{A\cap B_i},
\end{equation*}
an identity which is often useful.
\end{example}

\begin{lemma}
Let $F$ be the distribution function of $X$. Then
\begin{enumerate}[(a)]
    \item $\Prob(X>x) = 1-F(x)$, 
    \item $\Prob(x < X \leq y) = F(y) - F(x)$,
    \item $\Prob(X = x) = F(x) - \lim_{y \uparrow x} F(y)$.
\end{enumerate}
\end{lemma}

A random variable $X$ with distribution function $F$ is said to have two ``tails" given by 
\begin{equation*}
    T_1 (X) = \Prob(X > x) = 1 - F(x), \quad T_2(X) = \Prob(X \leq -x) = F(-x),    
\end{equation*}
where $x$ is large and positive. The rates at which the $T_i$ decay to zero as $x\to\infty$ have a substantial effect on the existence or non-existence of certain associated quantities called the ``moments" of the distribution. 


\section{Different random variables}
\subsection{Discrete random variables}
\begin{definition}
The random variable $X$ is called \textbf{discrete} if it takes values in some \textbf{countable} subset $\{ x_1, x_2, \dots \}$, only, of $\R$. The discrete random variable $X$ has \textbf{(probability) mass function} $f : \R \to [0, 1]$ given by $f(x) = \Prob(X = x)$. 
\end{definition}
We shall see that the distribution function of a discrete variable has jump discontinuities 
at the values $x_1 , x_2, \dots$ and is constant in between; such a distribution is called \emph{atomic}.

\subsection{Continuous random variables}
\begin{definition}
The random variable $X$ is called \textbf{continuous} if its distribution function can 
be expressed as 
\begin{equation*}
    F(x) = \int_{-\infty}^x f(u) du \qquad x \in \R
\end{equation*}
for some \textbf{integrable} function $f : \R \to [0, \infty)$ called the \textbf{(probability) density function} of $X$. 
\end{definition}
Some point worth noting:
\begin{enumerate}[(a)]
    \item The density function $f(x)$ is not unique. We can add some separate points to $f$, and it doesn't affect the integration.
    \item $F$ must be \textbf{absolutely continuous}. This implies $F$ is continuous. We can also deduce that the probability at certain point must be zero. \emph{i.e.}, $\Prob(X=x) = 0$.
\end{enumerate}

There is another sort of random variable, called ``singular".


\section{Random vectors}
\subsection{Definition}
The random vector is a function $X : \Omega \to \R^n$. For example, $\mathbf{X} = (X, Y)$ for $n=2$. We can also define the distribution function for such $X$. But we need to first introduce the ordering in $\R^n$.
\begin{center}
    By definition, $(x_1, y_1) < (x_2, y_2)$ if and only if $x_1 < x_2$  \textbf{AND}  $y_1 < y_2$.
\end{center}

\begin{definition}
The \textbf{joint distribution function} of a random vector $\mathbf{X} = (X_1, X_2 \dots, X_n)$ on the probability space $\{ \Omega, \mathcal{F}, \Prob \}$ is the function $F_{\mathbf{X}} : \R^n \to [0, 1]$ given by $F_{\mathbf{X}}(x) = \Prob(\mathbf{X} \leq \mathbf{x})$ for $\mathbf{x} \in \R^n$. 
\end{definition}

\begin{remark}
The joint probability $\Prob(\mathbf{X} \leq \mathbf{x}) = \Prob(X_1 \leq x_1, \dots, X_n \leq x_n)$. $\{\mathbf{X} \leq \mathbf{x} \}$ is an abbreviation for the event $\{\omega \in \Omega \spacevert \mathbf{X}(w) \leq \mathbf{x}\}$.
\end{remark}

\begin{lemma}
The joint distribution function $F_{X, Y}$ of the random vector $(X, Y)$ has the following properties: 
\begin{enumerate}[(a)]
    \item $\lim_{x, y\to -\infty} F_{X, Y}(x, y) = 0, \lim_{x,y\to\infty} F_{X, Y}(x,y) = 1$,
    \item if $(x_1, y_1) \leq (x_2, y_2)$, then $F_{X,Y}(x_1, y_1) \leq F_{X, Y}(x_2, y_2)$,
    \item $F_{X,Y}$ is continuous from above, in that 
    \begin{equation*}
        F_{X,Y}(x+u, y+v) \to F_{X,Y}(x,y) \quad as \quad u, v \downarrow 0.
    \end{equation*}
\end{enumerate}
\end{lemma}

\subsection{Marginalization} 
\begin{gather*}
    \lim_{y\to\infty} F_{X,Y} = F_X(x) = \Prob(X \leq x), \\
    \lim_{x\to\infty} F_{X,Y} = F_Y(y) = \Prob(Y \leq y).
\end{gather*}
The functions $F_X$ and $F_Y$ are called the ``marginal" distribution functions of $F_{X,Y}$. $F_{X,Y}$ can determine two marginals $F_X$ and $F_Y$, but \textbf{converse is NOT true}.

\subsection{Discrete and continuous distribution}
\begin{definition}
The random variables $X$ and $Y$ on the probability space $\{ \Omega, \mathcal{F}, \Prob \}$ are called \textbf{(jointly) discrete} if the vector $(X, Y)$ takes values in some \textbf{countable} subset of $\R^2$ only. The jointly discrete random variables $X, Y$ have \textbf{joint (probability) mass function} $f : \R^2 \to [0,1]$ given by $f(x, y) = \Prob(X = x, Y = y)$. 
\end{definition}

\begin{definition}
The random variables $X$ and $Y$ on the probability space $\{ \Omega, \mathcal{F}, \Prob \}$ are called \textbf{(jointly) continuous} if their joint distribution function can be expressed as 
\begin{equation*}
    F_{X,Y}(x,y) = \int_{u = -\infty}^x \int_{v = -\infty}^y f(u,v)du dv \qquad x, y\in\R,
\end{equation*}
for some \textbf{integrable} function $f : \R^2 \to [0, \infty)$ called the \textbf{joint (probability) density function} of the pair $(X, Y)$. 
\end{definition}

\end{document}